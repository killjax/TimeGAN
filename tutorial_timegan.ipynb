{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load original dataset and preprocess the loaded data.\n",
    "\n",
    "- data_name: stock, energy, or sine\n",
    "- seq_len: sequence length of the time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import real_data_loading\n",
    "from data_loading import real_data_processing\n",
    "from data_loading import label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data loading ---\n",
    "data_name = \"AAPL\"\n",
    "seq_len = 60\n",
    "start_date = \"2005-01-01\"\n",
    "end_date = \"2024-11-10\"\n",
    "\n",
    "ori_data = real_data_loading(data_name, start_date, end_date)\n",
    "\n",
    "print(f\"{data_name} dataset is ready. Number of sequences: {len(ori_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ori_data.head())\n",
    "\n",
    "all_names = ori_data.columns.get_level_values(0)\n",
    "feature_names= all_names.tolist()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Processing ---\n",
    "ori_data_x = real_data_processing(ori_data, seq_len)\n",
    "print(len(ori_data_x))\n",
    "print(ori_data_x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# --- MAIN EXECUTION ---\n",
    "#########################################################################\n",
    "\n",
    "# Your feature names in the correct order\n",
    "feature_names = [\n",
    "    'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume',\n",
    "    'Log_Return', 'ATR', 'BBW', 'MACD', 'MACD_Signal', 'RSI'\n",
    "]\n",
    "\n",
    "# Run the labeling function\n",
    "# 'ori_data' is the list you created in your previous code\n",
    "ori_data_s, metrics_df = label_data(ori_data_x, feature_names)\n",
    "\n",
    "# --- Check the results ---\n",
    "if ori_data_s:\n",
    "    print(f\"\\nExample 'ori_data' item shape: {ori_data_x[0].shape}\")\n",
    "    print(f\"Example 'ori_data_s' item: {ori_data_s[0]}\")\n",
    "\n",
    "    print(f\"\\nExample 'ori_data' item (another): {ori_data_x[-1].shape}\")\n",
    "    print(f\"Example 'ori_data_s' item (another): {ori_data_s[-1]}\")\n",
    "\n",
    "    print(f\"\\nTotal length of 'ori_data': {len(ori_data_x)}\")\n",
    "    print(f\"Total length of 'ori_data_s': {len(ori_data_s)}\")\n",
    "\n",
    "    # --- Optional Visualization ---\n",
    "    # This plot helps you confirm the labels make sense\n",
    "    print(\"\\nGenerating visualization of labeled clusters...\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(\n",
    "        data=metrics_df,\n",
    "        x='volatility',\n",
    "        y='mdd',\n",
    "        hue='label',\n",
    "        palette={'Normal': 'g', 'Volatile': 'b', 'Crisis': 'r'},\n",
    "        alpha=0.7,\n",
    "        s=30\n",
    "    )\n",
    "    plt.title('Market Regime Clusters (Labeled)', fontsize=16)\n",
    "    plt.xlabel('Volatility (Std. Dev. of Log Returns)', fontsize=12)\n",
    "    plt.ylabel('Maximum Drawdown (MDD)', fontsize=12)\n",
    "    plt.legend(title='Regime')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.savefig(\"market_regime_clusters.png\")\n",
    "    print(\"Saved cluster visualization to 'market_regime_clusters.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 11:29:04.652949: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-11 11:29:05.099808: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 11:29:08.510265: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "## Necessary packages\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. TimeGAN model\n",
    "from timegan import timegan\n",
    "# 3. Metrics\n",
    "from metrics.discriminative_metrics import discriminative_score_metrics\n",
    "from metrics.predictive_metrics import predictive_score_metrics\n",
    "from metrics.visualization_metrics import visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set network parameters\n",
    "\n",
    "TimeGAN network parameters should be optimized for different datasets.\n",
    "\n",
    "- module: gru, lstm, or lstmLN\n",
    "- hidden_dim: hidden dimensions\n",
    "- num_layer: number of layers\n",
    "- iteration: number of training iterations\n",
    "- batch_size: the number of samples in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Newtork parameters\n",
    "parameters = dict()\n",
    "\n",
    "parameters['module'] = 'gru'\n",
    "parameters['hidden_dim'] = 24\n",
    "parameters['num_layer'] = 3\n",
    "parameters['iterations'] = 10000\n",
    "parameters['batch_size'] = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TimeGAN for synthetic time-series data generation\n",
    "\n",
    "TimeGAN uses the original data and network parameters to return the generated synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TimeGAN\n",
    "generated_data_s, generated_data_x = timegan(ori_data_s, ori_data_x, parameters)\n",
    "print('Finish Synthetic Data Generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_idx = []\n",
    "crisis_idx = []\n",
    "vol_idx = []\n",
    "for i in range(len(generated_data_s)):\n",
    "    if np.argmax(generated_data_s[i]) == 0:\n",
    "        normal_idx.append(i)\n",
    "    elif np.argmax(generated_data_s[i]) == 1:\n",
    "        crisis_idx.append(i)\n",
    "    else:\n",
    "        vol_idx.append(i)\n",
    "\n",
    "generated_data_x_n = []\n",
    "for i in range(len(normal_idx)):\n",
    "    generated_data_x_n.append(generated_data_x[normal_idx[i]])\n",
    "generated_data_x_c = []\n",
    "for i in range(len(crisis_idx)):\n",
    "    generated_data_x_c.append(generated_data_x[crisis_idx[i]])\n",
    "generated_data_x_v = []\n",
    "for i in range(len(vol_idx)):\n",
    "    generated_data_x_v.append(generated_data_x[vol_idx[i]])\n",
    "\n",
    "nor_idx = []\n",
    "cri_idx = []\n",
    "vo_idx = []\n",
    "for i in range(len(ori_data_s)):\n",
    "    if ori_data_s[i] == [1.0,0.0,0.0]:\n",
    "        nor_idx.append(i)\n",
    "    elif ori_data_s[i] == [0.0,1.0,0.0]:\n",
    "        cri_idx.append(i)\n",
    "    else:\n",
    "        vo_idx.append(i)\n",
    "\n",
    "ori_data_x_n = []\n",
    "for i in range(len(nor_idx)):\n",
    "    ori_data_x_n.append(ori_data_x[nor_idx[i]])\n",
    "ori_data_x_c = []\n",
    "for i in range(len(cri_idx)):\n",
    "    ori_data_x_c.append(ori_data_x[cri_idx[i]])\n",
    "ori_data_x_v = []\n",
    "for i in range(len(vo_idx)):\n",
    "    ori_data_x_v.append(ori_data_x[vo_idx[i]])\n",
    "\n",
    "print(len(generated_data_x_n))\n",
    "print(len(ori_data_x_n))\n",
    "print(\"/\\n\")\n",
    "print(len(generated_data_x_c))\n",
    "print(len(ori_data_x_c))\n",
    "print(\"/\\n\")\n",
    "print(len(generated_data_x_v))\n",
    "print(len(ori_data_x_v))\n",
    "print(\"/\\n\")\n",
    "\n",
    "\n",
    "# print(ori_data_s[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generated_data_x_n.pkl', 'wb') as f:\n",
    "    pickle.dump(generated_data_x_n, f)\n",
    "with open('generated_data_x_c.pkl', 'wb') as f:\n",
    "    pickle.dump(generated_data_x_c, f)\n",
    "with open('generated_data_x_v.pkl', 'wb') as f:\n",
    "    pickle.dump(generated_data_x_v, f)\n",
    "with open('ori_data_x_n.pkl', 'wb') as f:\n",
    "    pickle.dump(ori_data_x_n, f)\n",
    "with open('ori_data_x_c.pkl', 'wb') as f:\n",
    "    pickle.dump(ori_data_x_c, f)\n",
    "with open('ori_data_x_v.pkl', 'wb') as f:\n",
    "    pickle.dump(ori_data_x_v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generated_data_x_n.pkl', 'rb') as f:\n",
    "    generated_data_x_loaded_n = pickle.load(f)\n",
    "with open('generated_data_x_c.pkl', 'rb') as f:\n",
    "    generated_data_x_loaded_c = pickle.load(f)\n",
    "with open('generated_data_x_v.pkl', 'rb') as f:\n",
    "    generated_data_x_loaded_v = pickle.load(f)\n",
    "with open('ori_data_x_n.pkl', 'rb') as f:\n",
    "    ori_data_x_loaded_n = pickle.load(f)\n",
    "with open('ori_data_x_c.pkl', 'rb') as f:\n",
    "    ori_data_x_loaded_c = pickle.load(f)\n",
    "with open('ori_data_x_v.pkl', 'rb') as f:\n",
    "    ori_data_x_loaded_v = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ori_data_n = len(ori_data_x_loaded_n)\n",
    "len_gen_data_n = len(generated_data_x_loaded_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Discriminative score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 11:29:58.538114: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "batch_generator() missing 1 required positional argument: 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(metric_iteration):\n\u001b[32m      5\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m len_ori_data_n > len_gen_data_n:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     temp_disc = \u001b[43mdiscriminative_score_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mori_data_x_loaded_n\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mlen_gen_data_n\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_data_x_loaded_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      8\u001b[39m     temp_disc = discriminative_score_metrics(ori_data_x_loaded_n, generated_data_x_loaded_n[:len_ori_data_n])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TimeGAN_Project/metrics/discriminative_metrics.py:135\u001b[39m, in \u001b[36mdiscriminative_score_metrics\u001b[39m\u001b[34m(ori_data, generated_data)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m itt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# Batch setting\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     X_mb_list, T_mb = \u001b[43mbatch_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m     X_hat_mb_list, T_hat_mb = batch_generator(train_x_hat, train_t_hat, batch_size)\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m# [FIXED BUG]: Pad the data from batch_generator to max_seq_len\u001b[39;00m\n\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# The `utils.batch_generator` returns a list of arrays of variable length\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# We must pad them to a consistent 3D array shape.\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: batch_generator() missing 1 required positional argument: 'batch_size'"
     ]
    }
   ],
   "source": [
    "metric_iteration = 5\n",
    "\n",
    "discriminative_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_n > len_gen_data_n:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_n[:len_gen_data_n], generated_data_x_loaded_n)\n",
    "  else:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_n, generated_data_x_loaded_n[:len_ori_data_n])\n",
    "  discriminative_score.append(temp_disc)\n",
    "\n",
    "print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predictive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_n > len_gen_data_n:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_n[:len_gen_data_n], generated_data_x_loaded_n)\n",
    "  else:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_n, generated_data_x_loaded_n[:len_ori_data_n])\n",
    "  predictive_score.append(temp_disc)\n",
    "\n",
    "print('predictive score: ' + str(np.round(np.mean(predictive_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len_ori_data_n < len_gen_data_n:\n",
    "    visualization(ori_data_x_loaded_n, generated_data_x_loaded_n[:len(ori_data_x_loaded_n)], 'pca')\n",
    "    visualization(ori_data_x_loaded_n, generated_data_x_loaded_n[:len(ori_data_x_loaded_n)], 'tsne')\n",
    "else:\n",
    "    visualization(ori_data_x_loaded_n[:len(generated_data_x_loaded_n)], generated_data_x_loaded_n, 'pca')\n",
    "    visualization(ori_data_x_loaded_n[:len(generated_data_x_loaded_n)], generated_data_x_loaded_n, 'tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ori_data_c = len(ori_data_x_loaded_c)\n",
    "len_gen_data_c = len(generated_data_x_loaded_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Discriminative score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminative_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_c > len_gen_data_c:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_c[:len_gen_data_c], generated_data_x_loaded_c)\n",
    "  else:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_c, generated_data_x_loaded_c[:len_ori_data_c])\n",
    "  discriminative_score.append(temp_disc)\n",
    "\n",
    "print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predictive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_c > len_gen_data_c:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_c[:len_gen_data_c], generated_data_x_loaded_c)\n",
    "  else:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_c, generated_data_x_loaded_c[:len_ori_data_c])\n",
    "  predictive_score.append(temp_disc)\n",
    "\n",
    "print('predictive score: ' + str(np.round(np.mean(predictive_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if len_ori_data_c < len_gen_data_c:\n",
    "    visualization(ori_data_x_loaded_c, generated_data_x_loaded_c[:len(ori_data_x_loaded_c)], 'pca')\n",
    "    visualization(ori_data_x_loaded_c, generated_data_x_loaded_c[:len(ori_data_x_loaded_c)], 'tsne')\n",
    "else:\n",
    "    visualization(ori_data_x_loaded_c[:len(generated_data_x_loaded_c)], generated_data_x_loaded_c, 'pca')\n",
    "    visualization(ori_data_x_loaded_c[:len(generated_data_x_loaded_c)], generated_data_x_loaded_c, 'tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ori_data_v = len(ori_data_x_loaded_v)\n",
    "len_gen_data_v = len(generated_data_x_loaded_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Discriminative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminative_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_v > len_gen_data_v:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_v[:len_gen_data_v], generated_data_x_loaded_v)\n",
    "  else:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_v, generated_data_x_loaded_v[:len_ori_data_v])\n",
    "  discriminative_score.append(temp_disc)\n",
    "\n",
    "print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predictive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_v > len_gen_data_v:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_v[:len_gen_data_v], generated_data_x_loaded_v)\n",
    "  else:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_v, generated_data_x_loaded_v[:len_ori_data_v])\n",
    "  predictive_score.append(temp_disc)\n",
    "\n",
    "print('predictive score: ' + str(np.round(np.mean(predictive_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len_ori_data_v < len_gen_data_v:\n",
    "    visualization(ori_data_x_loaded_v, generated_data_x_loaded_v[:len(ori_data_x_loaded_v)], 'pca')\n",
    "    visualization(ori_data_x_loaded_v, generated_data_x_loaded_v[:len(ori_data_x_loaded_v)], 'tsne')\n",
    "else:\n",
    "    visualization(ori_data_x_loaded_v[:len(generated_data_x_loaded_v)], generated_data_x_loaded_v, 'pca')\n",
    "    visualization(ori_data_x_loaded_v[:len(generated_data_x_loaded_v)], generated_data_x_loaded_v, 'tsne')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timegan_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load original dataset and preprocess the loaded data.\n",
    "\n",
    "- data_name: stock, energy, or sine\n",
    "- seq_len: sequence length of the time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import real_data_loading\n",
    "from data_loading import real_data_processing\n",
    "from data_loading import label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data loading ---\n",
    "data_name = \"AAPL\"\n",
    "seq_len = 60\n",
    "start_date = \"2005-01-01\"\n",
    "end_date = \"2024-11-10\"\n",
    "\n",
    "ori_data = real_data_loading(data_name, start_date, end_date)\n",
    "\n",
    "print(f\"{data_name} dataset is ready. Number of sequences: {len(ori_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ori_data.head())\n",
    "\n",
    "all_names = ori_data.columns.get_level_values(0)\n",
    "feature_names= all_names.tolist()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Processing ---\n",
    "ori_data_x = real_data_processing(ori_data, seq_len)\n",
    "print(len(ori_data_x))\n",
    "print(ori_data_x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# --- MAIN EXECUTION ---\n",
    "#########################################################################\n",
    "\n",
    "# Your feature names in the correct order\n",
    "feature_names = [\n",
    "    'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume',\n",
    "    'Log_Return', 'ATR', 'BBW', 'MACD', 'MACD_Signal', 'RSI'\n",
    "]\n",
    "\n",
    "# Run the labeling function\n",
    "# 'ori_data' is the list you created in your previous code\n",
    "ori_data_s, metrics_df = label_data(ori_data_x, feature_names)\n",
    "\n",
    "# --- Check the results ---\n",
    "if ori_data_s:\n",
    "    print(f\"\\nExample 'ori_data' item shape: {ori_data_x[0].shape}\")\n",
    "    print(f\"Example 'ori_data_s' item: {ori_data_s[0]}\")\n",
    "\n",
    "    print(f\"\\nExample 'ori_data' item (another): {ori_data_x[-1].shape}\")\n",
    "    print(f\"Example 'ori_data_s' item (another): {ori_data_s[-1]}\")\n",
    "\n",
    "    print(f\"\\nTotal length of 'ori_data': {len(ori_data_x)}\")\n",
    "    print(f\"Total length of 'ori_data_s': {len(ori_data_s)}\")\n",
    "\n",
    "    # --- Optional Visualization ---\n",
    "    # This plot helps you confirm the labels make sense\n",
    "    print(\"\\nGenerating visualization of labeled clusters...\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(\n",
    "        data=metrics_df,\n",
    "        x='volatility',\n",
    "        y='mdd',\n",
    "        hue='label',\n",
    "        palette={'Normal': 'g', 'Volatile': 'b', 'Crisis': 'r'},\n",
    "        alpha=0.7,\n",
    "        s=30\n",
    "    )\n",
    "    plt.title('Market Regime Clusters (Labeled)', fontsize=16)\n",
    "    plt.xlabel('Volatility (Std. Dev. of Log Returns)', fontsize=12)\n",
    "    plt.ylabel('Maximum Drawdown (MDD)', fontsize=12)\n",
    "    plt.legend(title='Regime')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.savefig(\"market_regime_clusters.png\")\n",
    "    print(\"Saved cluster visualization to 'market_regime_clusters.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Necessary packages\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. TimeGAN model\n",
    "from timegan import timegan\n",
    "# 3. Metrics\n",
    "from metrics.discriminative_metrics import discriminative_score_metrics\n",
    "from metrics.predictive_metrics import predictive_score_metrics\n",
    "from metrics.visualization_metrics import visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set network parameters\n",
    "\n",
    "TimeGAN network parameters should be optimized for different datasets.\n",
    "\n",
    "- module: gru, lstm, or lstmLN\n",
    "- hidden_dim: hidden dimensions\n",
    "- num_layer: number of layers\n",
    "- iteration: number of training iterations\n",
    "- batch_size: the number of samples in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Newtork parameters\n",
    "parameters = dict()\n",
    "\n",
    "parameters['module'] = 'gru'\n",
    "parameters['hidden_dim'] = 24\n",
    "parameters['num_layer'] = 3\n",
    "parameters['iterations'] = 10000\n",
    "parameters['batch_size'] = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TimeGAN for synthetic time-series data generation\n",
    "\n",
    "TimeGAN uses the original data and network parameters to return the generated synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TimeGAN\n",
    "generated_data_s, generated_data_x = timegan(ori_data_s, ori_data_x, parameters)\n",
    "print('Finish Synthetic Data Generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_idx = []\n",
    "crisis_idx = []\n",
    "vol_idx = []\n",
    "for i in range(len(generated_data_s)):\n",
    "    if np.argmax(generated_data_s[i]) == 0:\n",
    "        normal_idx.append(i)\n",
    "    elif np.argmax(generated_data_s[i]) == 1:\n",
    "        crisis_idx.append(i)\n",
    "    else:\n",
    "        vol_idx.append(i)\n",
    "\n",
    "generated_data_x_n = []\n",
    "for i in range(len(normal_idx)):\n",
    "    generated_data_x_n.append(generated_data_x[normal_idx[i]])\n",
    "generated_data_x_c = []\n",
    "for i in range(len(crisis_idx)):\n",
    "    generated_data_x_c.append(generated_data_x[crisis_idx[i]])\n",
    "generated_data_x_v = []\n",
    "for i in range(len(vol_idx)):\n",
    "    generated_data_x_v.append(generated_data_x[vol_idx[i]])\n",
    "\n",
    "nor_idx = []\n",
    "cri_idx = []\n",
    "vo_idx = []\n",
    "for i in range(len(ori_data_s)):\n",
    "    if ori_data_s[i] == [1.0,0.0,0.0]:\n",
    "        nor_idx.append(i)\n",
    "    elif ori_data_s[i] == [0.0,1.0,0.0]:\n",
    "        cri_idx.append(i)\n",
    "    else:\n",
    "        vo_idx.append(i)\n",
    "\n",
    "ori_data_x_n = []\n",
    "for i in range(len(nor_idx)):\n",
    "    ori_data_x_n.append(ori_data_x[nor_idx[i]])\n",
    "ori_data_x_c = []\n",
    "for i in range(len(cri_idx)):\n",
    "    ori_data_x_c.append(ori_data_x[cri_idx[i]])\n",
    "ori_data_x_v = []\n",
    "for i in range(len(vo_idx)):\n",
    "    ori_data_x_v.append(ori_data_x[vo_idx[i]])\n",
    "\n",
    "print(len(generated_data_x_n))\n",
    "print(len(ori_data_x_n))\n",
    "print(\"/\\n\")\n",
    "print(len(generated_data_x_c))\n",
    "print(len(ori_data_x_c))\n",
    "print(\"/\\n\")\n",
    "print(len(generated_data_x_v))\n",
    "print(len(ori_data_x_v))\n",
    "print(\"/\\n\")\n",
    "\n",
    "\n",
    "# print(ori_data_s[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generated_data_x_n.pkl', 'wb') as f:\n",
    "    pickle.dump(generated_data_x_n, f)\n",
    "with open('generated_data_x_c.pkl', 'wb') as f:\n",
    "    pickle.dump(generated_data_x_c, f)\n",
    "with open('generated_data_x_v.pkl', 'wb') as f:\n",
    "    pickle.dump(generated_data_x_v, f)\n",
    "with open('ori_data_x_n.pkl', 'wb') as f:\n",
    "    pickle.dump(ori_data_x_n, f)\n",
    "with open('ori_data_x_c.pkl', 'wb') as f:\n",
    "    pickle.dump(ori_data_x_c, f)\n",
    "with open('ori_data_x_v.pkl', 'wb') as f:\n",
    "    pickle.dump(ori_data_x_v, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('generated_data_x_n.pkl', 'rb') as f:\n",
    "    generated_data_x_loaded_n = pickle.load(f)\n",
    "with open('generated_data_x_c.pkl', 'rb') as f:\n",
    "    generated_data_x_loaded_c = pickle.load(f)\n",
    "with open('generated_data_x_v.pkl', 'rb') as f:\n",
    "    generated_data_x_loaded_v = pickle.load(f)\n",
    "with open('ori_data_x_n.pkl', 'rb') as f:\n",
    "    ori_data_x_loaded_n = pickle.load(f)\n",
    "with open('ori_data_x_c.pkl', 'rb') as f:\n",
    "    ori_data_x_loaded_c = pickle.load(f)\n",
    "with open('ori_data_x_v.pkl', 'rb') as f:\n",
    "    ori_data_x_loaded_v = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ori_data_n = len(ori_data_x_loaded_n)\n",
    "len_gen_data_n = len(generated_data_x_loaded_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Discriminative score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_iteration = 5\n",
    "\n",
    "discriminative_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_n > len_gen_data_n:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_n[:len_gen_data_n], generated_data_x_loaded_n)\n",
    "  else:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_n, generated_data_x_loaded_n[:len_ori_data_n])\n",
    "  discriminative_score.append(temp_disc)\n",
    "\n",
    "print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predictive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_n > len_gen_data_n:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_n[:len_gen_data_n], generated_data_x_loaded_n)\n",
    "  else:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_n, generated_data_x_loaded_n[:len_ori_data_n])\n",
    "  predictive_score.append(temp_disc)\n",
    "\n",
    "print('predictive score: ' + str(np.round(np.mean(predictive_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len_ori_data_n < len_gen_data_n:\n",
    "    visualization(ori_data_x_loaded_n, generated_data_x_loaded_n[:len(ori_data_x_loaded_n)], 'pca')\n",
    "    visualization(ori_data_x_loaded_n, generated_data_x_loaded_n[:len(ori_data_x_loaded_n)], 'tsne')\n",
    "else:\n",
    "    visualization(ori_data_x_loaded_n[:len(generated_data_x_loaded_n)], generated_data_x_loaded_n, 'pca')\n",
    "    visualization(ori_data_x_loaded_n[:len(generated_data_x_loaded_n)], generated_data_x_loaded_n, 'tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ori_data_c = len(ori_data_x_loaded_c)\n",
    "len_gen_data_c = len(generated_data_x_loaded_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Discriminative score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminative_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_c > len_gen_data_c:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_c[:len_gen_data_c], generated_data_x_loaded_c)\n",
    "  else:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_c, generated_data_x_loaded_c[:len_ori_data_c])\n",
    "  discriminative_score.append(temp_disc)\n",
    "\n",
    "print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predictive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_c > len_gen_data_c:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_c[:len_gen_data_c], generated_data_x_loaded_c)\n",
    "  else:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_c, generated_data_x_loaded_c[:len_ori_data_c])\n",
    "  predictive_score.append(temp_disc)\n",
    "\n",
    "print('predictive score: ' + str(np.round(np.mean(predictive_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if len_ori_data_c < len_gen_data_c:\n",
    "    visualization(ori_data_x_loaded_c, generated_data_x_loaded_c[:len(ori_data_x_loaded_c)], 'pca')\n",
    "    visualization(ori_data_x_loaded_c, generated_data_x_loaded_c[:len(ori_data_x_loaded_c)], 'tsne')\n",
    "else:\n",
    "    visualization(ori_data_x_loaded_c[:len(generated_data_x_loaded_c)], generated_data_x_loaded_c, 'pca')\n",
    "    visualization(ori_data_x_loaded_c[:len(generated_data_x_loaded_c)], generated_data_x_loaded_c, 'tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ori_data_v = len(ori_data_x_loaded_v)\n",
    "len_gen_data_v = len(generated_data_x_loaded_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Discriminative Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminative_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_v > len_gen_data_v:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_v[:len_gen_data_v], generated_data_x_loaded_v)\n",
    "  else:\n",
    "    temp_disc = discriminative_score_metrics(ori_data_x_loaded_v, generated_data_x_loaded_v[:len_ori_data_v])\n",
    "  discriminative_score.append(temp_disc)\n",
    "\n",
    "print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predictive Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  if len_ori_data_v > len_gen_data_v:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_v[:len_gen_data_v], generated_data_x_loaded_v)\n",
    "  else:\n",
    "    temp_disc = predictive_score_metrics(ori_data_x_loaded_v, generated_data_x_loaded_v[:len_ori_data_v])\n",
    "  predictive_score.append(temp_disc)\n",
    "\n",
    "print('predictive score: ' + str(np.round(np.mean(predictive_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len_ori_data_v < len_gen_data_v:\n",
    "    visualization(ori_data_x_loaded_v, generated_data_x_loaded_v[:len(ori_data_x_loaded_v)], 'pca')\n",
    "    visualization(ori_data_x_loaded_v, generated_data_x_loaded_v[:len(ori_data_x_loaded_v)], 'tsne')\n",
    "else:\n",
    "    visualization(ori_data_x_loaded_v[:len(generated_data_x_loaded_v)], generated_data_x_loaded_v, 'pca')\n",
    "    visualization(ori_data_x_loaded_v[:len(generated_data_x_loaded_v)], generated_data_x_loaded_v, 'tsne')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timegan_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load original dataset and preprocess the loaded data.\n",
    "\n",
    "- data_name: stock, energy, or sine\n",
    "- seq_len: sequence length of the time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loading import real_data_loading\n",
    "from data_loading import real_data_processing\n",
    "from data_loading import label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data loading ---\n",
    "data_name = \"AAPL\"\n",
    "seq_len = 60\n",
    "start_date = \"2005-01-01\"\n",
    "end_date = \"2024-11-10\"\n",
    "\n",
    "ori_data = real_data_loading(data_name, start_date, end_date)\n",
    "\n",
    "print(f\"{data_name} dataset is ready. Number of sequences: {len(ori_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ori_data.head())\n",
    "\n",
    "all_names = ori_data.columns.get_level_values(0)\n",
    "feature_names= all_names.tolist()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Processing ---\n",
    "ori_data_x = real_data_processing(ori_data, seq_len)\n",
    "print(len(ori_data_x))\n",
    "print(ori_data_x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# --- MAIN EXECUTION ---\n",
    "#########################################################################\n",
    "\n",
    "# Your feature names in the correct order\n",
    "feature_names = [\n",
    "    'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume',\n",
    "    'Log_Return', 'ATR', 'BBW', 'MACD', 'MACD_Signal', 'RSI'\n",
    "]\n",
    "\n",
    "# Run the labeling function\n",
    "# 'ori_data' is the list you created in your previous code\n",
    "ori_data_s, metrics_df = label_data(ori_data_x, feature_names)\n",
    "\n",
    "# --- Check the results ---\n",
    "if ori_data_s:\n",
    "    print(f\"\\nExample 'ori_data' item shape: {ori_data_x[0].shape}\")\n",
    "    print(f\"Example 'ori_data_s' item: {ori_data_s[0]}\")\n",
    "\n",
    "    print(f\"\\nExample 'ori_data' item (another): {ori_data_x[-1].shape}\")\n",
    "    print(f\"Example 'ori_data_s' item (another): {ori_data_s[-1]}\")\n",
    "\n",
    "    print(f\"\\nTotal length of 'ori_data': {len(ori_data_x)}\")\n",
    "    print(f\"Total length of 'ori_data_s': {len(ori_data_s)}\")\n",
    "\n",
    "    # --- Optional Visualization ---\n",
    "    # This plot helps you confirm the labels make sense\n",
    "    print(\"\\nGenerating visualization of labeled clusters...\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(\n",
    "        data=metrics_df,\n",
    "        x='volatility',\n",
    "        y='mdd',\n",
    "        hue='label',\n",
    "        palette={'Normal': 'g', 'Volatile': 'b', 'Crisis': 'r'},\n",
    "        alpha=0.7,\n",
    "        s=30\n",
    "    )\n",
    "    plt.title('Market Regime Clusters (Labeled)', fontsize=16)\n",
    "    plt.xlabel('Volatility (Std. Dev. of Log Returns)', fontsize=12)\n",
    "    plt.ylabel('Maximum Drawdown (MDD)', fontsize=12)\n",
    "    plt.legend(title='Regime')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.savefig(\"market_regime_clusters.png\")\n",
    "    print(\"Saved cluster visualization to 'market_regime_clusters.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Necessary packages\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. TimeGAN model\n",
    "from timegan import timegan\n",
    "# 3. Metrics\n",
    "from metrics.discriminative_metrics import discriminative_score_metrics\n",
    "from metrics.predictive_metrics import predictive_score_metrics\n",
    "from metrics.visualization_metrics import visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set network parameters\n",
    "\n",
    "TimeGAN network parameters should be optimized for different datasets.\n",
    "\n",
    "- module: gru, lstm, or lstmLN\n",
    "- hidden_dim: hidden dimensions\n",
    "- num_layer: number of layers\n",
    "- iteration: number of training iterations\n",
    "- batch_size: the number of samples in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Newtork parameters\n",
    "parameters = dict()\n",
    "\n",
    "parameters['module'] = 'gru'\n",
    "parameters['hidden_dim'] = 24\n",
    "parameters['num_layer'] = 3\n",
    "parameters['iterations'] = 22\n",
    "parameters['batch_size'] = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TimeGAN for synthetic time-series data generation\n",
    "\n",
    "TimeGAN uses the original data and network parameters to return the generated synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TimeGAN\n",
    "generated_data_s, generated_data_x = timegan(ori_data_s, ori_data_x, parameters)\n",
    "print('Finish Synthetic Data Generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(generated_data_s)):\n",
    "    print(generated_data_s[i])\n",
    "print(len(generated_data_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the generated data\n",
    "\n",
    "### 1. Discriminative score\n",
    "\n",
    "To evaluate the classification accuracy between original and synthetic data using post-hoc RNN network. The output is |classification accuracy - 0.5|.\n",
    "\n",
    "- metric_iteration: the number of iterations for metric computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_iteration = 5\n",
    "\n",
    "discriminative_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  temp_disc = discriminative_score_metrics(ori_data_x, generated_data_x)\n",
    "  discriminative_score.append(temp_disc)\n",
    "\n",
    "print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the generated data\n",
    "\n",
    "### 2. Predictive score\n",
    "\n",
    "To evaluate the prediction performance on train on synthetic, test on real setting. More specifically, we use Post-hoc RNN architecture to predict one-step ahead and report the performance in terms of MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_score = list()\n",
    "for tt in range(metric_iteration):\n",
    "  temp_pred = predictive_score_metrics(ori_data, generated_data_x)\n",
    "  predictive_score.append(temp_pred)\n",
    "\n",
    "print('Predictive score: ' + str(np.round(np.mean(predictive_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the generated data\n",
    "\n",
    "### 3. Visualization\n",
    "\n",
    "We visualize the original and synthetic data distributions using PCA and tSNE analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(ori_data_x, generated_data_x, 'pca')\n",
    "visualization(ori_data_x, generated_data_x, 'tsne')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timegan_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
